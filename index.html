<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>TJNav</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">TJNav</h1>
      <h2 class="project-tagline">TJHSST Robotics Lab</h2>
      <a href="https://github.com/yukioyama/robot-localization" class="btn">View on GitHub</a>
    </section>

    <section class="main-content">
      <h2>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Description</h2>
TJNav is a project by Yuki Oyama and Ethan Liu at the Thomas Jefferson High School for Science and Technology Robotics Lab.  The goal of our project is to create an indoor navigation robot that is capable of guiding a user to any room within the building at TJ.  While this project is specific to our building, given any map of any building, it should be able to navigate just as well.
      
      <h2>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Details</h2>
      The project consists of two-stages.  Stage one consists of the robot's localization ability.  To address the problem of localization, we utilized LIDAR sensor data for error correction and IMU & VESC Motor Controller Odometry data.  We feed this data into an Adaptive Monte Carlo Algorithm in order to create a probability density function to determine the most likely postition of the robot at each time frame.  Stage two consists of the robot's navigation ability.  To accomplish navigation throughout the TJHSST building, we implement the A-star Algorithm using distance heuristics to determine the shortest path a robot must traverseâ€”the rooms represent nodes of the graph.
       <h2>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code</h2>
      
  
      
       Local_costmap_parameters.txt: Updated 5/12
      <pre><code>  
      local_costmap:
  global_frame: odom
  robot_base_frame: base_link
  update_frequency: 2.0
  publish_frequency: 2.0
  static_map: false
  rolling_window: true
  width: 6.0
  height: 6.0
  resolution: 0.01

controller_frequency: 2.0

</code></pre>
      
       Global_costmap_parameters.txt: Updated 5/12
      <pre><code>  
     global_costmap:
  global_frame: /map
  robot_base_frame: base_link
  update_frequency: 2.0
  static_map: true


</code></pre>
       Common_costmap_parameters.txt: Updated 5/12
      <pre><code>    
   obstacle_range: 10.0
raytrace_range: 12.0
footprint: [[-0.22, 0.26], [0.22, 0.26], [0.22, -0.26], [-0.22, -0.26]]
inflation_radius: 0.5

observation_sources: laser_scan_sensor
laser_scan_sensor: {sensor_frame: laser, data_type: LaserScan, topic: scan, marking: true, clearing: true}

</code></pre>
      
     
      Move_base.launch: Updated 5/12
      <img src="movebasecode.png" style="max-width:100%;">
      
      
             <h2>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Components</h2>
             <h2>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logs</h2>
      11/1:Finished soldering battery connector circuit.  Project order forms complete for XT60 connectors/Acrylic for chassis. <br />      
     
      11/14:Finished creating computer aided design for new electronics board panel (see photo1 galery)<br />
     
      11/30:XT60 Order Confirmation from Amazon<br />
      12//3: Robot moved upon connection w/ battery connector with 2 3000mAh Batteries in series <br />
      12/13: Tested Jetson by booting via direct power source (not in robot circuit)<br />
      2/10: Develop code for pathfinding (python script to be run in launch file)<br />
      2/14: Resoldered battery connector using XT60 Connectors<br />
      <img src="connector.png" style="max-width:100%;">
      4/14: Created Map of School for area near Robotics Lab<br />
      <img src="binarymap.png" style="max-width:100%;">
      4/16: Created yml file for our specific map to tell robot dimensions of pixel/meter ratio<br />
      4/22: Successfully ran teleop program and began running robot around without HDMI connection by SSHing to the robot <br/>
      5/1: Tested the SLAM mapping ability of robot. <br/>
      <img src="badmap.png" style="max-width:100%;"> <br/>
      An example of when the robot moves at 4m/s.  Map is extremely faulty and completely disoriented.  <br/>
      <img src="goodmap.png" style="max-width:100%;"> <br/>
      An example of when the robot moves at 1m/s with pauses every 2 seconds.  Map of same area is much more defined. <br/>
      5/12: Developed move base code and various configuration files (which can be seen in the code section).  Able to navigate with relative accuracy from point A to B.  Obstacle avoidance also worked as shown in images below. <br/>
      <img src="obstacledirect.png" style="max-width:100%;">
      <img src="obstacleavoid.png" style="max-width:100%;"></br>
      5/16: Developed hardware to attach on robot, allowing it to carry materials.</br>
  <img src="greenbox.png" style="max-width:100%;"> </br>
5/18: Updated schematic
<img src="Screen Shot 2018-05-31 at 9.16.53 PM.png" style="max-width:100%;">
      <h2>
      
       
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gallery</h2>
                   <img src="Platformcad.png" style="max-width:100%;">
                   Photo 1. Panel on which VESC, IMU, and LIDAR will be mounted
                   <h2>
     <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>
<h2>      
  	We were able to utilize various sensor topic channels to achieve a degree of autonomous movement from point A to point B, however, the AMCL was not tuned well enough to accurately navigate the school. Our results provide a framework for future studies to tune and improve upon the robot to complete the project fully.  Implementing 3D navigation capabilities (navigating ramps and stairs) is a potential future area of study.

<a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Discussion</h2>

      <div id="disqus_thread"></div>
<script>
var disqus_config = function () {
this.page.url = PAGE_URL; 
this.page.identifier = PAGE_IDENTIFIER;
};
(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://https-yukioyama-github-io-robot-localization.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/yukioyama/robot-localization">TJNav</a> is maintained by <a href="https://github.com/yukioyama">yukioyama</a>.</span>
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>

    </section>

  </body>
</html>
